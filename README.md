# SparkKafkaStreaming

docker-compose-demo-app.yml - поднятие Kafka-брокера и spark-кластера локально 
(приложение пока не работает со спарк-кластером, так как для структурированных стримов из кафки нужно додеплоивать 
библиотеку spark-sql-kafka-0-10 на кластер, а я пока с этим не разбирался)

LogGenerator - генератор случайного количества случайных логов. В параметры принимает URL кафка-брокера, топик и имя 
хоста, которым надо подписываться в логах. То есть, для имитации нескольких хостов надо запустить несколько приложений 
с разными названиями хостов.

SparkProcessingApp - обработка логов спарком (пока локально)

ResultConsumer - чтение собщений из кафка-топика. В параметрах нужно указать URL брокера и топик.

SparkProcessingAppTest - попытка написать тетст провалилась, так как я не смог придумать, как протестировать
структурированный спарк-стриминг с окнами и ватермарками с помощью библиотеки "com.holdenkarau" %% "spark-testing-base". Надо придумывать другой способ.
